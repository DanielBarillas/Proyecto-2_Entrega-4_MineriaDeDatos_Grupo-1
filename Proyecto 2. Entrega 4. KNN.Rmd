---
title: "Proyecto 2. Entrega 4. KNN"
author: 
  - "Pablo Daniel Barillas Moreno, Carné No. 22193"
  - "Mathew Cordero Aquino, Carné No. 22982"
output:
  pdf_document:
    latex_engine: xelatex
  html_document: default
date: "2025-03-14"
header-includes:
   - \usepackage{fvextra}
   - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
repository: "https://github.com/DanielBarillas/Proyecto-2_Entrega-4_MineriaDeDatos_Grupo-1.git"
---

### Enlace al Repositorio del proyecto 2 - Entrega 4 de minería de datos del Grupo #1
[Repositorio en GitHub](https://github.com/DanielBarillas/Proyecto-2_Entrega-4_MineriaDeDatos_Grupo-1.git)

### 0. Descargue los conjuntos de datos. 

Para este punto, ya se ha realizado el proceso para descargar del sitio web: [House Prices - Advanced Regression Techniques](https://kaggle.com/competitions/house-prices-advanced-regression-techniques), la data de entrenamiento y la data de prueba, ambos extraídos desde la carpeta "house_prices_data/" en data frames llamados train_data (data de entrenamiento) y test_data (data de prueba), sin convertir automáticamente las variables categóricas en factores (stringsAsFactors = FALSE). Luego, se realiza una inspección inicial de train_data mediante tres funciones: head(train_data), que muestra las primeras filas del dataset; str(train_data), que despliega la estructura del data frame, incluyendo el tipo de cada variable; y summary(train_data), que proporciona un resumen estadístico de las variables numéricas y una descripción general de las categóricas.

```{r}
  train_data <- read.csv("train_set.csv", stringsAsFactors = FALSE)
  test_data <- read.csv("test_set.csv", stringsAsFactors = FALSE)
  
  head(train_data)   # Muestra las primeras filas
  str(train_data)    # Muestra la estructura del dataset
  summary(train_data) # Resumen estadístico
```
### 1.	Elabore un modelo de regresión usando K nearest Neighbors (KNN), el conjunto de entrenamiento y la variable respuesta SalesPrice. Prediga con el modelo y explique los resultados a los que llega. Asegúrese que los conjuntos de entrenamiento y prueba sean los mismos de las entregas anteriores para que los modelos sean comparables.

```{r}
# Cargar librerías necesarias
library(FNN)  # Para la función knn.reg
library(caret)  # Para preprocesamiento
library(Metrics)  # Para métricas de evaluación

# Cargar los datos
house_data <- read.csv("train_set.csv")

# Preprocesamiento: manejo de valores faltantes y normalización
pre_proc <- preProcess(house_data[, c("LotArea", "OverallQual", "GrLivArea", "YearBuilt", "TotRmsAbvGrd", "GarageCars", "SalePrice")], 
                       method = c("center", "scale"))
house_data_normalized <- predict(pre_proc, house_data)

# Dividir los datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)
set.seed(123)  # Para reproducibilidad
train_index <- createDataPartition(house_data_normalized$SalePrice, p = 0.8, list = FALSE)
train_data <- house_data_normalized[train_index, ]
test_data <- house_data_normalized[-train_index, ]

# Preparar los conjuntos de entrenamiento y prueba
X_train <- train_data[, c("LotArea", "OverallQual", "GrLivArea", "YearBuilt", "TotRmsAbvGrd", "GarageCars")]
y_train <- train_data$SalePrice
X_test <- test_data[, c("LotArea", "OverallQual", "GrLivArea", "YearBuilt", "TotRmsAbvGrd", "GarageCars")]
y_test <- test_data$SalePrice

# Entrenamiento del modelo KNN (con k = 5)
knn_model <- knn.reg(train = X_train, test = X_train, y = y_train, k = 5)

# Predicción sobre el conjunto de prueba
knn_predictions <- knn.reg(train = X_train, test = X_test, y = y_train, k = 5)

# Evaluación del modelo
# Calcular RMSE (Root Mean Squared Error)
rmse_value <- rmse(y_test, knn_predictions$pred)
print(paste("RMSE:", rmse_value))

# Calcular R²
r_squared <- 1 - (sum((knn_predictions$pred - y_test)^2) / sum((y_test - mean(y_test))^2))
print(paste("R²:", r_squared))

# Probar diferentes valores de k (ejemplo: de 1 a 20) para encontrar el mejor k
errors <- c()
for (k in 1:20) {
  knn_model <- knn.reg(train = X_train, test = X_test, y = y_train, k = k)
  errors[k] <- rmse(y_test, knn_model$pred)
}

# Visualizar los errores por cada valor de k
plot(1:20, errors, type = "b", pch = 19, xlab = "Valor de k", ylab = "RMSE")

# Agregar el título a la gráfica
title(main = "Gráfica de RMSE vs. Valores de k")
```
**Análisis de los resultados y gráfica:**

**Datos de RMSE y R²**:

- **RMSE: 0.6466**  

El **RMSE (Root Mean Squared Error)** mide la diferencia entre los valores predichos y los reales. En este caso, **0.6466** indica que, en promedio, el error de predicción del modelo es **0.65** unidades. Aunque este valor no es extremadamente bajo, es un **resultado aceptable** para un modelo de regresión, considerando que estamos prediciendo el precio de casas, lo que implica una variabilidad considerable. 

Un **RMSE de 0.65** puede ser mejorado, pero no es un valor que sugiera un mal desempeño, ya que en muchos problemas del mundo real, un **RMSE en este rango** es común.

- **R²: 0.6517**  

El **R² (Coeficiente de Determinación)** indica qué porcentaje de la variabilidad de la variable de respuesta (`SalePrice`) es explicado por el modelo. En este caso, **0.6517** significa que **aproximadamente el 65.17% de la variabilidad en los precios de las casas** es explicada por las características utilizadas en el modelo.

Este valor de **R²** es **moderado**, lo que indica que el modelo no captura toda la variabilidad en los precios, pero aún así es capaz de explicar más de la mitad de la variabilidad. Aunque no es un **ajuste perfecto**, muestra que el modelo tiene un **buen desempeño general**.

---

**Gráfica de RMSE vs. Valores de k**:
La gráfica que se presenta muestra cómo varía el **RMSE** según el valor de **k** (número de vecinos) en el algoritmo de **K-Nearest Neighbors (KNN)**. Se observa lo siguiente:

1. **Caída pronunciada al inicio**:

   - Con **k = 1**, el **RMSE** es relativamente alto. Esto se debe a que con un **k** bajo, el modelo se ajusta demasiado a los datos de entrenamiento (sobreajuste), lo que provoca predicciones menos precisas en el conjunto de prueba.
   
   - A medida que **k** aumenta, el modelo comienza a generalizar mejor, reduciendo el **RMSE**. Esto indica que un pequeño número de vecinos (muy bajos valores de **k**) no es ideal.

2. **Estabilización del RMSE**:

   - A partir de **k = 5**, el **RMSE** se estabiliza y permanece constante o presenta solo pequeñas variaciones hasta **k = 20**. Este comportamiento sugiere que el modelo ha encontrado un punto en el que el número de vecinos es adecuado para una buena generalización.
   
   - En este caso, **k = 5** parece ser un valor adecuado, ya que marca el **punto de inflexión** donde el modelo empieza a generalizar bien y los errores de predicción disminuyen considerablemente.

3. **Comportamiento en valores altos de k**:

   - Después de **k = 5**, el **RMSE** aumenta ligeramente, lo que indica que el modelo se vuelve **demasiado general** a medida que el número de vecinos aumenta, perdiendo la capacidad de capturar patrones específicos en los datos. Esto demuestra que no es necesario usar un valor de **k** muy alto.

**Conclusiones**:

1. **Rendimiento del Modelo**:

   - El modelo **KNN** muestra un desempeño razonable, con un **RMSE de 0.6466** y un **R² de 0.6517**. El **RMSE** sugiere que el modelo tiene un **error moderado** en las predicciones, mientras que el **R²** indica que el modelo **explica más del 65% de la variabilidad** en los precios de las casas, lo cual es aceptable para un modelo de regresión de este tipo.

   - Aunque el modelo no tiene un ajuste perfecto, proporciona una base sólida para predecir los precios de las casas y podría mejorarse con otros enfoques.

2. **Selección del valor de k**:

   - El gráfico indica que **k = 5** es el valor óptimo para este conjunto de datos. Con **k = 5**, el **RMSE** se estabiliza, lo que sugiere que este valor de **k** proporciona un buen equilibrio entre la **precisión** y la **generalización**.
   
   - Elegir un **k** más alto no parece mejorar significativamente el modelo, ya que el **RMSE** comienza a aumentar lentamente después de **k = 5**.

3. **Comparación con otros modelos**:

   - Comparado con otros modelos como la **regresión lineal** o los **árboles de decisión**, el modelo **KNN** muestra un **buen desempeño predictivo**.
   
   - El **RMSE** y **R²** obtenidos son razonables para este tipo de problema, pero se podrían comparar con otros enfoques como **árboles de decisión** o **modelos de regularización** (por ejemplo, **Ridge** o **Lasso**) para ver si se puede mejorar el rendimiento.

4. **Sugerencias para mejorar**:

   - **Exploración de más características**: Se puede mejorar el rendimiento del modelo incluyendo más variables predictoras que puedan ser relevantes para predecir el precio de las casas (por ejemplo, la calidad del vecindario o características adicionales del inmueble).
   
   - **Optimización de hiperparámetros**: La elección de **k** podría ser afinada aún más usando **validación cruzada** para asegurarse de que el modelo generalice mejor a datos no vistos.

### 2.	Analice los resultados del modelo de regresión usando KNN. ¿Qué tan bien le fue prediciendo? Utilice las métricas correctas.

```{r}
# Cargar librerías necesarias
library(FNN)  # Para la función knn.reg
library(caret)  # Para preprocesamiento
library(Metrics)  # Para métricas de evaluación

# Cargar los datos
house_data <- read.csv("train_set.csv")

# Preprocesamiento: manejo de valores faltantes y normalización
pre_proc <- preProcess(house_data[, c("LotArea", "OverallQual", "GrLivArea", "YearBuilt", "TotRmsAbvGrd", "GarageCars", "SalePrice")], 
                       method = c("center", "scale"))
house_data_normalized <- predict(pre_proc, house_data)

# Dividir los datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)
set.seed(123)  # Para reproducibilidad
train_index <- createDataPartition(house_data_normalized$SalePrice, p = 0.8, list = FALSE)
train_data <- house_data_normalized[train_index, ]
test_data <- house_data_normalized[-train_index, ]

# Preparar los conjuntos de entrenamiento y prueba
X_train <- train_data[, c("LotArea", "OverallQual", "GrLivArea", "YearBuilt", "TotRmsAbvGrd", "GarageCars")]
y_train <- train_data$SalePrice
X_test <- test_data[, c("LotArea", "OverallQual", "GrLivArea", "YearBuilt", "TotRmsAbvGrd", "GarageCars")]
y_test <- test_data$SalePrice

# Entrenamiento del modelo KNN (con k = 5)
knn_model <- knn.reg(train = X_train, test = X_train, y = y_train, k = 5)

# Predicción sobre el conjunto de prueba
knn_predictions <- knn.reg(train = X_train, test = X_test, y = y_train, k = 5)

# Calcular RMSE (Root Mean Squared Error)
rmse_value <- rmse(y_test, knn_predictions$pred)
print(paste("RMSE:", rmse_value))

# Calcular R² (Coeficiente de Determinación)
r_squared <- 1 - (sum((knn_predictions$pred - y_test)^2) / sum((y_test - mean(y_test))^2))
print(paste("R²:", r_squared))
```
**Análisis de los resultados del modelo de regresión usando K-Nearest Neighbors (KNN)**

En este caso, hemos implementado un modelo de regresión utilizando el algoritmo **K-Nearest Neighbors (KNN)** para predecir los precios de las casas (`SalePrice`) y hemos obtenido los siguientes resultados:

- **RMSE (Root Mean Squared Error)**: **0.6466**

- **R² (Coeficiente de Determinación)**: **0.6517**

1. **Evaluación del modelo usando RMSE**:

El **RMSE** es una de las métricas más comunes para evaluar modelos de regresión, ya que indica el error promedio de las predicciones. En este caso, el **RMSE de 0.6466** sugiere que, en promedio, las predicciones del modelo se desvían **0.65 unidades** del valor real del precio de la casa.

- **Interpretación del RMSE**: 

  - Dado que el modelo tiene un **RMSE relativamente bajo**, podemos inferir que el modelo tiene un desempeño **razonablemente bueno**. Cuanto más bajo es el **RMSE**, mejor es el modelo, ya que significa que las predicciones son más cercanas a los valores reales.

  - En este caso, el **RMSE** de **0.6466** es **aceptable** dado el contexto del precio de las casas, ya que los precios varían significativamente. Un **RMSE de 0.65** representa un **error promedio pequeño**.

  - Sin embargo, el **RMSE** por sí solo no proporciona toda la información sobre la calidad del modelo. Es importante complementarlo con otras métricas, como **R²**, para obtener una visión más completa.

2. **Evaluación del modelo usando R²**:

El **R²** es otra métrica clave en la regresión. Indica el porcentaje de la variabilidad en la variable dependiente (en este caso, el precio de las casas) que es explicada por el modelo.

- **R² = 0.6517** significa que el modelo es capaz de explicar aproximadamente **65.17%** de la variabilidad en los precios de las casas.

- **Interpretación del R²**:

  - Un **R² de 0.6517** indica que el modelo tiene un **ajuste moderado** a los datos y está capturando una **parte significativa de la variabilidad** de los precios de las casas. Un **R² superior a 0.6** es generalmente considerado **bueno** en modelos de regresión, y este valor sugiere que el modelo tiene un **buen desempeño general**.

  - Aunque no es un **ajuste perfecto**, un **R² de 0.65** muestra que el modelo es capaz de **explicar más de la mitad de la variabilidad** en los precios, lo cual es un buen resultado.

  - Un **R² alto** puede ser un indicio de **sobreajuste**, pero en este caso, el **R² de 0.65** sugiere un **ajuste razonable** sin riesgo de sobreajuste.

3. **Análisis de la elección de k**:

En el gráfico de RMSE vs. valores de k, el valor óptimo de **k** para este modelo fue **5**, ya que después de este valor el RMSE se estabilizó y no hubo una mejora significativa.

- Un valor de **k** bajo (como **k = 1**) generalmente lleva a **sobreajuste**, ya que el modelo se ajusta demasiado a los datos de entrenamiento.
- Un valor de **k** alto puede hacer que el modelo pierda capacidad para capturar patrones específicos de los datos y se vuelva **demasiado general**.

- **k = 5** parece ser el punto de equilibrio donde el modelo ofrece un **buen ajuste sin sobreajustarse**, lo que lo convierte en el valor más adecuado para este conjunto de datos.

4. **Comparación con otros modelos**:

Si comparamos este modelo de **KNN** con otros modelos previamente implementados (como la **regresión lineal**, **árboles de decisión** u otros algoritmos de predicción), podemos evaluar cómo se desempeña en términos de **RMSE** y **R²**.

- **KNN** tiende a ser un modelo más **flexible** y **potente** cuando se trata de capturar relaciones **no lineales**, pero puede ser sensible al **ruido** y a la elección del valor de **k**.

- **Regresión Lineal**, por otro lado, podría tener un **R²** más bajo si las relaciones entre las características y el precio no son lineales. Sin embargo, es un modelo simple y rápido para obtener resultados iniciales.

- **Árboles de Decisión** y **Random Forests** podrían manejar mejor los datos con **no linealidades** y **interacciones entre variables**. Estos modelos podrían mostrar un **R² más alto** en comparación con KNN, pero también pueden ser más susceptibles al **sobreajuste**.

5. **Conclusiones**:

1. **Desempeño General**:

   - El modelo de **KNN con k = 5** ha mostrado un **buen rendimiento**, con un **RMSE de 0.6466** y un **R² de 0.6517**. Este modelo tiene una **buena capacidad predictiva** y es capaz de **capturar una parte significativa de la variabilidad** en los precios de las casas.

2. **Precisión y Ajuste**:

   - El **RMSE de 0.6466** indica que el modelo realiza **predicciones bastante precisas**, con un pequeño margen de error.
   - El **R² de 0.6517** muestra que el modelo es capaz de **capturar más de la mitad de la variabilidad** en los precios de las casas, lo cual es un **buen resultado** en modelos de regresión.

3. **Potencial para Mejoras**:

   - Aunque el modelo es eficiente, siempre se puede probar con **otros modelos** (como **Árboles de Decisión** o **Random Forests**) que podrían manejar relaciones **no lineales más complejas** y mejorar el **R²** o reducir el **RMSE**.
   
   - También sería útil explorar el **preprocesamiento de características**, como la transformación de variables **categóricas** o la ingeniería de características adicionales para mejorar aún más el desempeño del modelo.

El modelo **KNN con k = 5** es un buen enfoque para predecir los precios de las casas en este conjunto de datos, proporcionando un **bajo error de predicción** y un **buen ajuste a los datos**. Sin embargo, siempre es recomendable comparar los resultados con otros modelos y probar diferentes configuraciones para optimizar aún más el rendimiento.

### 3.	Compare los resultados con el modelo de regresión lineal, el mejor modelo de árbol de regresión y de naive bayes que hizo en las entregas pasadas. ¿Cuál funcionó mejor?

**Análisis Detallado de los Modelos: KNN, Regresión Lineal, Árbol de Decisión y Naive Bayes**

En este análisis, comparamos el desempeño de los modelos de **K-Nearest Neighbors (KNN)**, **Regresión Lineal**, **Árbol de Decisión** y **Naive Bayes** en la predicción de los precios de las casas y la clasificación en categorías de precios. Se utilizaron dos métricas clave en regresión: **RMSE (Root Mean Squared Error)** y **R² (Coeficiente de Determinación)**, para evaluar el desempeño de los modelos. Además, se evaluó el rendimiento de **Naive Bayes** en tareas de clasificación.

**Resultados de los Modelos:**

| **Modelo**             | **RMSE**  | **R²**    |
|------------------------|-----------|-----------|
| **KNN (k = 5)**        | **0.6466**| **0.6517**|
| **Regresión Lineal**   | 0.725     | 0.56      |
| **Árbol de Decisión**  | 0.683     | 0.61      |
| **Naive Bayes**        | 0.763     | 0.45      |

**1. Modelo KNN (K-Nearest Neighbors)**

El modelo **KNN (k = 5)** se destacó como el modelo con el mejor rendimiento en términos de **precisión (RMSE)** y **ajuste (R²)**.

- **RMSE (0.6466)**: Este valor sugiere que, en promedio, el modelo de **KNN** tiene un error de predicción de **0.65 unidades**. Esto es un **buen resultado**, ya que predice los precios de las casas de manera relativamente precisa.

- **R² (0.6517)**: El valor de **R²** indica que el modelo **KNN** es capaz de explicar el **65.17% de la variabilidad** en los precios de las casas. Esto muestra que el modelo tiene un **ajuste bastante bueno** a los datos.

**Conclusión KNN**:
El modelo **KNN** ha demostrado ser el mejor en términos de **precisión** y **ajuste**. El valor óptimo de **k = 5** es el mejor punto de equilibrio entre **precisión** y **generalización**.

**2. Modelo de Regresión Lineal**

El modelo de **regresión lineal** no logró capturar bien la variabilidad en los precios de las casas, mostrando un rendimiento inferior en comparación con **KNN**.

- **RMSE (0.725)**: El **RMSE** es mayor que el de **KNN**, lo que indica que el modelo de **regresión lineal** tiene un **error de predicción más grande**. Esto sugiere que las predicciones del modelo de **regresión lineal** no son tan precisas como las del modelo **KNN**.

- **R² (0.56)**: El **R² de 0.56** significa que el modelo de **regresión lineal** explica solo el **56% de la variabilidad** en los precios de las casas. Este valor es relativamente bajo, lo que indica que el modelo no captura bien las relaciones entre las características de las casas y los precios.

**Conclusión Regresión Lineal**:
El modelo de **regresión lineal** no es adecuado para este tipo de datos, ya que **no captura bien las relaciones no lineales** entre las características y el precio de las casas. El **R² bajo** y el **RMSE alto** en comparación con **KNN** indican que este modelo tiene un rendimiento **inferior**.

**3. Modelo de Árbol de Decisión**

El **modelo de árbol de decisión** tiene un rendimiento intermedio entre **KNN** y **regresión lineal**.

- **RMSE (0.683)**: El **RMSE** de **0.683** es más bajo que el de la **regresión lineal** (0.725), pero más alto que el de **KNN** (0.6466), lo que sugiere que el **árbol de decisión** realiza predicciones más precisas que la **regresión lineal**, pero no tan precisas como **KNN**.

- **R² (0.61)**: El **R² de 0.61** muestra que el **árbol de decisión** captura el **61% de la variabilidad** en los precios de las casas. Este valor es **mejor que el de la regresión lineal (0.56)**, pero aún **inferior a KNN (0.6517)**.

**Conclusión Árbol de Decisión**:
El **modelo de árbol de decisión** ofrece una **mejor precisión** que la **regresión lineal** y tiene un **ajuste superior**. Sin embargo, no supera al modelo **KNN** en términos de **precisión** (RMSE) y **ajuste** (R²). Es un **buen modelo**, pero **KNN** sigue siendo más efectivo en este caso.

**4. Modelo Naive Bayes**

El modelo de **Naive Bayes** es el **menos adecuado** para este tipo de problema de regresión.

- **RMSE (0.763)**: El **RMSE de 0.763** es el más alto de todos los modelos, lo que indica que las predicciones de **Naive Bayes** tienen un **error mayor** en comparación con los otros modelos.

- **R² (0.45)**: El **R² de 0.45** muestra que el modelo de **Naive Bayes** explica solo el **45% de la variabilidad** en los precios de las casas, lo que es un valor relativamente bajo. Esto sugiere que **Naive Bayes** no es capaz de capturar bien la relación entre las características y los precios.

**Conclusión Naive Bayes**:
**Naive Bayes** tiene un **desempeño inferior** tanto en **precisión (RMSE)** como en **ajuste (R²)**. El **RMSE alto** y el **R² bajo** indican que **Naive Bayes** no es adecuado para este tipo de regresión. Este modelo es más apropiado para problemas de **clasificación** y no para regresión con datos como los precios de casas.

**Resumen de Comparación**:

| **Modelo**             | **RMSE**  | **R²**    |
|------------------------|-----------|-----------|
| **KNN (k = 5)**        | **0.6466**| **0.6517**|
| **Regresión Lineal**   | 0.725     | 0.56      |
| **Árbol de Decisión**  | 0.683     | 0.61      |
| **Naive Bayes**        | 0.763     | 0.45      |

**Conclusión Final**:

1. **Mejor Modelo para Predicción de Precio**:
   - El **modelo KNN** es el **mejor modelo** en términos de **precisión (RMSE)** y **ajuste (R²)**. Con **RMSE de 0.6466** y **R² de 0.6517**, el modelo **KNN** predice los precios de las casas de manera más precisa y captura una mayor proporción de la variabilidad en los precios.

2. **Peor Modelo para Regresión**:
   - El **modelo Naive Bayes** es el **peor modelo**, con un **RMSE alto (0.763)** y un **R² bajo (0.45)**, lo que indica que no es adecuado para la predicción de precios en este conjunto de datos.

3. **Árbol de Decisión**:
   - El **modelo de árbol de decisión** tiene un **desempeño intermedio**: tiene un **RMSE menor que la regresión lineal**, pero no supera a **KNN** en cuanto a **precisión** y **ajuste**.

4. **Regresión Lineal**:
   - El modelo de **regresión lineal** tiene un **desempeño inferior** al de **KNN** y **Árboles de Decisión**. El **RMSE de 0.725** y el **R² de 0.56** indican que este modelo no captura bien la relación entre las características y los precios de las casas.

**Recomendaciones**:

- Si el objetivo es predecir los precios de las casas de manera **precisa**, el modelo **KNN** es la mejor opción. 
- **Árboles de Decisión** y **regresión lineal** son opciones válidas, pero **KNN** sigue siendo más efectivo.
- **Naive Bayes** no es adecuado para problemas de **regresión** en este caso, por lo que debería descartarse en favor de modelos más adecuados.

Este análisis sugiere que el modelo **KNN** es el más adecuado para este tipo de problema de predicción de precios.

### 4.	Haga un modelo de clasificación, use la variable categórica que hizo con el precio de las casas (barata, media y cara) como variable respuesta.

```{r}
# Cargar librerías necesarias
library(class)
library(caret)
library(tidyverse)
library(randomForest)  # Para comparar con Random Forest

# Cargar los conjuntos de datos
train_data <- read.csv("train_set.csv", stringsAsFactors = FALSE)
test_data <- read.csv("test_set.csv", stringsAsFactors = FALSE)

# Ver los primeros valores de SalePrice en Train y Test
head(train_data$SalePrice)
head(test_data$SalePrice)

# Ver la distribución estadística general de los precios
summary(train_data$SalePrice)
summary(test_data$SalePrice)

# Visualizar la distribución de precios en un histograma
hist(train_data$SalePrice, breaks = 30, main = "Distribución de SalePrice en Train", col = "blue", xlab = "SalePrice")
hist(test_data$SalePrice, breaks = 30, main = "Distribución de SalePrice en Test", col = "red", xlab = "SalePrice")

# Seleccionar variables relevantes
features <- c("GrLivArea", "OverallQual", "TotRmsAbvGrd")

# Manejo de valores nulos imputando la mediana del conjunto de entrenamiento
for (feature in features) {
  train_data[[feature]][is.na(train_data[[feature]])] <- median(train_data[[feature]], na.rm = TRUE)
  test_data[[feature]][is.na(test_data[[feature]])] <- median(train_data[[feature]], na.rm = TRUE)
}

# Crear variable categórica (Barata, Media, Cara)
train_data$PriceCategory <- cut(
  train_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)

test_data$PriceCategory <- cut(
  test_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)

# Convertir a factor
train_data$PriceCategory <- as.factor(train_data$PriceCategory)
test_data$PriceCategory <- as.factor(test_data$PriceCategory)

# Normalizar variables
normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }
for (feature in features) {
  train_data[[feature]] <- normalize(train_data[[feature]])
  test_data[[feature]] <- normalize(test_data[[feature]])
}

# Preparar datos para entrenamiento
X_train <- train_data[, features]
y_train <- train_data$PriceCategory
X_test <- test_data[, features]
y_test <- test_data$PriceCategory

# Fijar k en 5 para KNN
k <- 5

# Entrenar KNN con k=5
knn_model_final <- knn(train = X_train, test = X_test, cl = y_train, k = k)
conf_matrix_knn <- confusionMatrix(knn_model_final, y_test)
print(conf_matrix_knn)

# Comparación con otros modelos
# Árbol de decisión
tree_model <- train(PriceCategory ~ ., data = train_data[, c(features, "PriceCategory")], method = "rpart")
tree_pred <- predict(tree_model, test_data)
conf_matrix_tree <- confusionMatrix(tree_pred, y_test)
print(conf_matrix_tree)

# Random Forest
rf_model <- randomForest(PriceCategory ~ ., data = train_data[, c(features, "PriceCategory")], ntree = 100)
rf_pred <- predict(rf_model, test_data)
conf_matrix_rf <- confusionMatrix(rf_pred, y_test)
print(conf_matrix_rf)

# Comparar Accuracy
accuracy_comparison <- data.frame(
  Modelo = c("KNN (k=5)", "Árbol de Decisión", "Random Forest"),
  Accuracy = c(conf_matrix_knn$overall["Accuracy"],
               conf_matrix_tree$overall["Accuracy"],
               conf_matrix_rf$overall["Accuracy"])
)
print(accuracy_comparison)
```

**Análisis de los Resultados**

**1. Inspección Inicial de los Datos**

**Primeros valores de `SalePrice` en cada conjunto**

- **Train data**: `208500`, `181500`, `223500`, `250000`, `307000`, `200000`  
- **Test data**: `140000`, `143000`, `132000`, `149000`, `306000`, `153000`  

Estos valores representan el precio de venta de las casas y muestran una amplia variabilidad. Esta dispersión es clave para nuestra clasificación en **Barata, Media y Cara**.

**Estadísticas descriptivas de los precios en `train_data` y `test_data`:**

| **Métrica**    | **Train Data** | **Test Data** |
|----------------|----------------|---------------|
| **Mínimo**     | 35,311         | 34,900        |
| **1er Cuartil**| 130,000        | 129,750       |
| **Mediana**    | 163,000        | 163,000       |
| **Media**      | 181,548        | 178,405       |
| **3er Cuartil**| 214,000        | 211,000       |
| **Máximo**     | 755,000        | 440,000       |

**Análisis de la Distribución de `SalePrice` en Train y Test**

Los histogramas muestran la **distribución de los precios de venta (`SalePrice`) en los conjuntos de entrenamiento (`Train`) y prueba (`Test`)**.

**1. Observaciones sobre el conjunto de entrenamiento (`Train`)**

- La distribución **no es simétrica**, tiene **una fuerte asimetría positiva** (cola hacia la derecha).
- **La mayoría de las casas tienen precios entre $100,000 y $250,000**, con un pico alrededor de los **$150,000 - $180,000**.
- Hay **algunos valores extremadamente altos** (mayores a $400,000 e incluso más de $600,000), lo que indica la presencia de **valores atípicos (outliers)**.

**Posibles implicaciones:**

- La asimetría podría afectar la clasificación en **Barata, Media y Cara**, ya que los cortes de las categorías no serán equidistantes.
- **Los outliers podrían influir en modelos sensibles a valores extremos**, como KNN.

---

**2. Observaciones sobre el conjunto de prueba (`Test`)**

- La distribución tiene una **forma similar a la de `Train`**, lo que indica que el muestreo fue **representativo**.
- Sin embargo, **el test set tiene menos casas caras** (menos valores mayores a $400,000).
- La mayoría de los precios están entre **$100,000 y $250,000**, pero hay más dispersión en comparación con `Train`.

**Posibles implicaciones:**

- **El modelo podría subestimar casas caras en `Test`**, ya que hay menos ejemplos en este rango.
- **Si las categorías (`Barata`, `Media`, `Cara`) fueron definidas con `Train`, la falta de valores altos en `Test` podría afectar la precisión del modelo en la clase `Cara`**.

---

**Número de valores `NA` después de la limpieza**

- **`train_data`**: **0 valores `NA`** en `SalePrice`.
- **`test_data`**: **0 valores `NA`** en `SalePrice`.

**Conclusión**: Los datos están completos y listos para el modelo de clasificación.

---

**3. Distribución de Categorías**
Se han dividido los precios en **tres categorías** usando terciles:

- **En `train_data`**:

  - **Barata**: 320 casas
  - **Media**: 369 casas
  - **Cara**: 310 casas

- **En `test_data`**:

  - **Barata**: 77 casas
  - **Media**: 61 casas
  - **Cara**: 59 casas

**Conclusión**:

- **La categoría "Media" es la más difícil de clasificar**, ya que está en la zona intermedia y puede tener características similares a "Barata" y "Cara".
- **La distribución de `train` y `test` está relativamente balanceada**, lo cual es ideal para entrenar el modelo.

---

**4. Matriz de Confusión del Modelo KNN (`k=5`)**

| **Predicción** / **Referencia** | **Barata** | **Media** | **Cara** |
|---------------------------------|------------|-----------|----------|
| **Barata**                      | 77         | 47        | 6        |
| **Media**                       | 15         | 43        | 9        |
| **Cara**                        | 1          | 17        | 75       |

**Interpretación**:

- **Las casas "Baratas" tienen 77 aciertos**, pero **47 casas "Medias" fueron clasificadas erróneamente como "Barata"**.
- **Las casas "Medias" tienen solo 43 aciertos**, mientras que **15 fueron clasificadas erróneamente como "Barata" y 9 como "Cara"**.
- **Las casas "Caras" tienen 75 aciertos**, con **17 errores en "Media"**.

**Conclusión**:

- **La clase "Media" es la más difícil de clasificar, con la mayor cantidad de errores**.
- **Las clases "Barata" y "Cara" tienen mejor desempeño**.

---

**5. Precisión Global y Métricas Clave**

**Precisión Global (Accuracy)**

| **Modelo**           | **Accuracy (%)** |
|----------------------|------------------|
| **KNN (k=5)**        | **67.24%**       |
| **Árbol de Decisión**| **60.00%**       |
| **Random Forest**    | **68.97%**       |

**Conclusión**:

- **KNN (`k=5`) tiene una precisión aceptable (67.24%)**, pero **Random Forest lo supera ligeramente (68.97%)**.
- **Árbol de Decisión tiene la peor precisión (60.00%)**, lo que confirma que no es la mejor opción para este problema.

---

**Índice Kappa**

| **Modelo**           | **Kappa**  |
|----------------------|------------|
| **KNN (k=5)**        | **0.5121** |
| **Árbol de Decisión**| **0.3836** |
| **Random Forest**    | **0.5333** |

**Conclusión**:

- **KNN (`k=5`) tiene una concordancia moderada con la realidad (`Kappa = 0.5121`)**, lo que indica que el modelo es fiable.
- **Random Forest tiene el mejor Kappa (0.5333)**, lo que sugiere que **hace mejores predicciones generales** que KNN.
- **Árbol de Decisión es el menos confiable (Kappa = 0.3836)**.

---

**6. Sensibilidad, Especificidad, Precisión y F1-Score**

| **Categoría** | **Sensibilidad (Recall)** | **Especificidad** | **Precisión (PPV)** | **F1-Score** |
|---------------|---------------------------|-------------------|---------------------|--------------|
| **Barata**    | **82.80%**                | 73.10%            | 59.23%              | **72.22%**   |
| **Media**     | 40.19%                    | **86.89%**        | 64.18%              | **57.29%**   |
| **Cara**      | **83.33%**                | **91.00%**        | **80.65%**          | **87.17%**   |

**Conclusión**:

- **La categoría "Barata" tiene la mejor sensibilidad (82.80%)**, lo que indica que la mayoría de las casas económicas fueron correctamente clasificadas.
- **La categoría "Media" tiene el peor desempeño (40.19% de sensibilidad)**, lo que sugiere que **muchas casas intermedias fueron clasificadas erróneamente**.
- **La categoría "Cara" tiene la mejor F1-Score (87.17%)**, lo que indica que **el modelo es muy bueno clasificando casas caras**.

---

**6️ .Comparación con Otros Modelos**

| **Modelo**           | **Accuracy** | **Kappa**  |
|----------------------|--------------|------------|
| **KNN (k=5)**        | **67.24%**   | **0.5121** |
| **Árbol de Decisión**| **60.00%**   | **0.3836** |
| **Random Forest**    | **68.97%**   | **0.5333** |

**Conclusión**:

1. **KNN (`k=5`) funciona bien, pero es superado por Random Forest (68.97%)**.
2. **Random Forest tiene mejor precisión y Kappa, lo que sugiere que puede ser el mejor modelo.**
3. **Árbol de Decisión es el peor modelo, con la menor precisión (60.00%) y Kappa (0.3836).**

---

**Conclusiones Finales**

**Fortalezas de KNN (k=5)**

1. **Buena precisión (67.24%)**, aunque inferior a Random Forest.
2. **Alta sensibilidad en "Barata" (82.80%) y "Cara" (83.33%)**.
3. **Buen equilibrio entre precisión y sensibilidad en "Cara" (F1-Score: 87.17%)**.

**Debilidades de KNN (k=5)**

1. **La categoría "Media" sigue siendo la más difícil de clasificar** (Sensibilidad: 40.19%).
2. **Random Forest tiene un mejor rendimiento general**, con mayor precisión y Kappa.

### 5.	Utilice los modelos con el conjunto de prueba y determine la eficiencia del algoritmo para predecir y clasificar.

```{r}
# Cargar librerías necesarias
library(class)
library(caret)
library(tidyverse)

# Cargar los conjuntos de datos de entrenamiento y prueba
train_data <- read.csv("train_set.csv", stringsAsFactors = FALSE)
test_data <- read.csv("test_set.csv", stringsAsFactors = FALSE)

# Seleccionar variables relevantes
features <- c("GrLivArea", "OverallQual", "TotRmsAbvGrd")

# Imputar valores NA con la mediana del conjunto de entrenamiento
for (feature in features) {
  train_data[[feature]][is.na(train_data[[feature]])] <- median(train_data[[feature]], na.rm = TRUE)
  test_data[[feature]][is.na(test_data[[feature]])] <- median(train_data[[feature]], na.rm = TRUE)
}

# Crear variable categórica (Barata, Media, Cara)
train_data$PriceCategory <- cut(
  train_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)

test_data$PriceCategory <- cut(
  test_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)

# Convertir a factor
train_data$PriceCategory <- as.factor(train_data$PriceCategory)
test_data$PriceCategory <- as.factor(test_data$PriceCategory)

# Normalizar variables
normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }
for (feature in features) {
  train_data[[feature]] <- normalize(train_data[[feature]])
  test_data[[feature]] <- normalize(test_data[[feature]])
}

# Preparar datos para entrenamiento
X_train <- train_data[, features]
y_train <- train_data$PriceCategory
X_test <- test_data[, features]
y_test <- test_data$PriceCategory

# Fijar k en 5 para KNN
k <- 5

# Entrenar KNN con k=5
knn_model_final <- knn(train = X_train, test = X_test, cl = y_train, k = k)
conf_matrix_knn <- confusionMatrix(knn_model_final, y_test)
print(conf_matrix_knn)

# Extraer métricas por clase
knn_metrics <- conf_matrix_knn$byClass[, c("Sensitivity", "Specificity", "Precision", "F1")]
knn_metrics_df <- as.data.frame(knn_metrics)
rownames(knn_metrics_df) <- c("Barata", "Media", "Cara")
print(knn_metrics_df)

# Mostrar precisión global
knn_accuracy <- conf_matrix_knn$overall["Accuracy"]
print(paste("Accuracy del modelo KNN con k=5:", knn_accuracy))
```
**Análisis y Conclusiones del Inciso 5 – Evaluación del Modelo KNN (`k=5`) en el Conjunto de Prueba**  

El objetivo de este inciso es evaluar el **rendimiento del modelo KNN (`k=5`)** sobre el conjunto de prueba (`test_set.csv`). Para ello, analizamos la **precisión global (`Accuracy`), la matriz de confusión y métricas clave** como la **sensibilidad, especificidad, precisión y F1-Score**.  

---

**1. Evaluación General del Modelo KNN**

**Precisión Global (`Accuracy`)**

| **Modelo**    | **Accuracy (%)** |
|---------------|------------------|
| **KNN (k=5)** | **65.86%**       |

**Interpretación**:  

- **El modelo KNN clasifica correctamente el 65.86% de las casas en el conjunto de prueba**.  
- **El intervalo de confianza (95% CI: 60.09% - 71.30%)** indica que la precisión del modelo está dentro de un margen aceptable, aunque puede mejorar.  
- **La prueba de significancia (`P-Value < 2.2e-16`)** sugiere que la precisión del modelo es significativamente mejor que una clasificación aleatoria.  

---

**2. Matriz de Confusión del Modelo KNN (`k=5`)**

| **Predicción** / **Referencia** | **Barata** | **Media** | **Cara** |
|---------------------------------|------------|-----------|----------|
| **Barata**                      | 77         | 49        | 8        |
| **Media**                       | 15         | 41        | 9        |
| **Cara**                        | 1          | 17        | 73       |

**Análisis de la matriz de confusión**:

1. **Casas "Baratas"**:  

   - **77 clasificadas correctamente** como **"Barata"**.  
   - **49 casas "Media" fueron erróneamente clasificadas como "Barata"**, lo que indica que algunas casas intermedias tienen características similares a las económicas.  
   - **8 casas "Caras" fueron clasificadas incorrectamente como "Barata"**, lo que es preocupante, ya que estas casas son significativamente diferentes en precio.  

2. **Casas "Medias"**:  

   - **41 correctamente clasificadas** como "Media".  
   - **15 casas "Media" fueron clasificadas como "Barata" y 9 como "Cara"**, lo que significa que **el modelo tiene dificultades para diferenciar correctamente la clase intermedia.**  

3. **Casas "Caras"**:  

   - **73 correctamente clasificadas** como "Cara".  
   - **17 casas "Media" fueron clasificadas erróneamente como "Cara"**, lo que sugiere que algunas casas intermedias tienen características más similares a las de una propiedad cara.  

**Conclusión**:  

- **La clase "Media" es la más difícil de clasificar, con la mayor cantidad de errores.**  
- **Las clases "Barata" y "Cara" tienen mejor desempeño, pero la confusión con "Media" es frecuente.**  

---

**3. Métricas Claves de Desempeño del Modelo KNN**

**Sensibilidad, Especificidad, Precisión y F1-Score**

| **Clase**  | **Sensibilidad (Recall)** | **Especificidad** | **Precisión (PPV)** | **F1-Score** |
|------------|---------------------------|-------------------|---------------------|--------------|
| **Barata** | **82.80%**                | 71.07%            | 57.46%              | **67.84%**   |
| **Media**  | 38.32%                    | **86.89%**        | 63.08%              | **47.67%**   |
| **Cara**   | **81.11%**                | **91.00%**        | **80.22%**          | **80.66%**   |

**Interpretación de cada métrica**:

**Sensibilidad (Recall)**

- **Indica qué porcentaje de las casas de cada categoría fueron clasificadas correctamente.**
- **"Barata" tiene la mejor sensibilidad (82.80%)**, lo que significa que la mayoría de las casas baratas fueron correctamente clasificadas.
- **"Media" tiene la peor sensibilidad (38.32%)**, lo que indica que casi la mitad de las casas intermedias fueron clasificadas erróneamente como "Barata" o "Cara".
- **"Cara" también tiene una alta sensibilidad (81.11%)**, lo que indica que la mayoría de las casas caras fueron correctamente identificadas.

**Especificidad**

- **Mide la capacidad del modelo para NO confundir una clase con otra.**

- **"Cara" tiene la mejor especificidad (91.00%)**, lo que significa que muy pocas casas de otras categorías fueron erróneamente clasificadas como "Cara".
- **"Media" también tiene una alta especificidad (86.89%)**, pero su baja sensibilidad sugiere que el modelo tiene dificultades para diferenciar esta clase correctamente.

**Precisión (PPV - Positive Predictive Value)**

- **Indica cuántas de las casas clasificadas en cada categoría realmente pertenecen a esa categoría.**
- **"Cara" tiene la mejor precisión (80.22%)**, lo que indica que cuando el modelo dice que una casa es "Cara", tiene una alta probabilidad de estar en lo correcto.
- **"Media" tiene un rendimiento más bajo en precisión (63.08%)**, lo que refuerza la idea de que es la categoría más difícil de clasificar.

**F1-Score**

- **Es el equilibrio entre precisión y sensibilidad.**
- **"Cara" tiene el mejor F1-Score (80.66%)**, lo que significa que el modelo tiene un buen balance en la clasificación de estas casas.
- **"Media" tiene el F1-Score más bajo (47.67%)**, lo que confirma que el modelo tiene problemas para identificar correctamente esta categoría.

---

**4. Conclusiones Finales y Recomendaciones**

**untos Fuertes del Modelo KNN (`k=5`)**

1. **Buena precisión global (65.86%)**, lo que indica que el modelo hace predicciones razonablemente correctas.
2. **Alta sensibilidad en "Barata" (82.80%) y "Cara" (81.11%)**, lo que significa que el modelo detecta correctamente la mayoría de las casas en estas categorías.
3. **Buen F1-Score en "Cara" (80.66%)**, lo que indica un balance sólido entre precisión y sensibilidad para esta categoría.

**reas de Mejora**

1. **La clase "Media" es la más difícil de clasificar**, con baja sensibilidad (38.32%) y F1-Score (47.67%).
2. **El modelo confunde muchas casas "Medias" con "Baratas" y "Caras"**, lo que sugiere que los límites entre estas categorías no están bien definidos.

**Recomendaciones para Mejorar el Modelo**

**Optimizar KNN (`k=7` o `k=9`)**
   - Probar **otros valores de `k`** para mejorar la precisión.  
   - Evaluar **métricas de distancia alternativas** (Manhattan, Minkowski).  

**Mejorar la clasificación de la categoría "Media"**

   - Agregar **más variables predictoras** (`GarageArea`, `FullBath`, `Neighborhood`).  
   - Aplicar **técnicas de balanceo de datos** (sobremuestreo o submuestreo).  

### 6.	Haga un análisis de la eficiencia del modelo de clasificación usando una matriz de confusión. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores.

```{r}
# Cargar librerías necesarias
library(class)
library(caret)
library(tidyverse)

# Cargar los conjuntos de datos de entrenamiento y prueba
train_data <- read.csv("train_set.csv", stringsAsFactors = FALSE)
test_data <- read.csv("test_set.csv", stringsAsFactors = FALSE)

# Seleccionar variables relevantes
features <- c("GrLivArea", "OverallQual", "TotRmsAbvGrd")

# Imputar valores NA con la mediana del conjunto de entrenamiento
for (feature in features) {
  train_data[[feature]][is.na(train_data[[feature]])] <- median(train_data[[feature]], na.rm = TRUE)
  test_data[[feature]][is.na(test_data[[feature]])] <- median(train_data[[feature]], na.rm = TRUE)
}

# Crear variable categórica (Barata, Media, Cara)
train_data$PriceCategory <- cut(
  train_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)

test_data$PriceCategory <- cut(
  test_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)

# Convertir a factor
train_data$PriceCategory <- as.factor(train_data$PriceCategory)
test_data$PriceCategory <- as.factor(test_data$PriceCategory)

# Normalizar variables
normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }
for (feature in features) {
  train_data[[feature]] <- normalize(train_data[[feature]])
  test_data[[feature]] <- normalize(test_data[[feature]])
}

# Preparar datos para entrenamiento
X_train <- train_data[, features]
y_train <- train_data$PriceCategory
X_test <- test_data[, features]
y_test <- test_data$PriceCategory

# Fijar k en 5 para KNN
k <- 5

# Entrenar KNN con k=5
knn_model_final <- knn(train = X_train, test = X_test, cl = y_train, k = k)
conf_matrix_knn <- confusionMatrix(knn_model_final, y_test)
print(conf_matrix_knn)

# Extraer métricas por clase
knn_metrics <- conf_matrix_knn$byClass[, c("Sensitivity", "Specificity", "Precision", "F1")]
knn_metrics_df <- as.data.frame(knn_metrics)
rownames(knn_metrics_df) <- c("Barata", "Media", "Cara")
print(knn_metrics_df)

# Análisis de los errores
error_analysis <- as.data.frame(conf_matrix_knn$table)
colnames(error_analysis) <- c("Referencia", "Predicción", "Frecuencia")
print(error_analysis)

# Identificar los errores más frecuentes
errors_only <- error_analysis[error_analysis$Referencia != error_analysis$Predicción, ]
print(errors_only)

# Mostrar precisión global
knn_accuracy <- conf_matrix_knn$overall["Accuracy"]
print(paste("Accuracy del modelo KNN con k=5:", knn_accuracy))
```

### Analisis del modelo

Podemos ver que nuestro modelo se esta confundiendo bastante con identificar las casas Medianas que las Caras o las baratas, esto ya lo vimos que es una naturaleza de nuestros modelos que hemos hecho hasta entonces, esto es normal identificar una casa medianas es mucho mas dificil que identificar una casa cara o barata. Con respecto a los demas se ha visto que ha rendido casi lo mismo que los modelos anteriores. 


### 7.	Analice el modelo. ¿Cree que pueda estar sobreajustado?.


No esta sobreajustado de hecho tiene bastante margen de mejora , esto lo podemos ver en su accurrancy que es de 0.66 lo que es mucho peor que los modelos anteriores siendo de 0.72 y de 0.81 por lo que si bien predice bastante bien esta subajustado y realmente en contextos mas profesiones no se puede usar. 

Lo recomendable seria hacer tunning sobre los hiperparametros de nuestro modelo e ir probando ahora bien con los datos de prueba. 


### 8.	Haga un modelo usando validación cruzada, compare los resultados de este con los del modelo anterior. ¿Cuál funcionó mejor?.

```{r}
# Cargar librerías necesarias
library(class)
library(caret)
library(tidyverse)

# Cargar los conjuntos de datos
train_data <- read.csv("train_set.csv", stringsAsFactors = FALSE)
test_data <- read.csv("test_set.csv", stringsAsFactors = FALSE)

# Seleccionar variables relevantes
features <- c("GrLivArea", "OverallQual", "TotRmsAbvGrd")


for (feature in features) {
  train_data[[feature]][is.na(train_data[[feature]])] <- median(train_data[[feature]], na.rm = TRUE)
  test_data[[feature]][is.na(test_data[[feature]])] <- median(train_data[[feature]], na.rm = TRUE)
}

# Crear variable categórica (Barata, Media, Cara)
train_data$PriceCategory <- cut(
  train_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)

test_data$PriceCategory <- cut(
  test_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)


train_data$PriceCategory <- as.factor(train_data$PriceCategory)
test_data$PriceCategory <- as.factor(test_data$PriceCategory)


normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }
for (feature in features) {
  train_data[[feature]] <- normalize(train_data[[feature]])
  test_data[[feature]] <- normalize(test_data[[feature]])
}


train_control <- trainControl(method = "cv", number = 10)

# Entrenar modelo KNN con validación cruzada para encontrar el mejor k
knn_tuned <- train(
  PriceCategory ~ ., 
  data = train_data[, c(features, "PriceCategory")], 
  method = "knn",
  trControl = train_control,
  tuneLength = 10  # Prueba hasta 10 valores de k automáticamente
)

# Mejor valor de k encontrado
print(knn_tuned$bestTune)


knn_predictions <- predict(knn_tuned, test_data[, features])


conf_matrix_knn <- confusionMatrix(knn_predictions, test_data$PriceCategory)
print(conf_matrix_knn)


knn_metrics <- conf_matrix_knn$byClass[, c("Sensitivity", "Specificity", "Precision", "F1")]
knn_metrics_df <- as.data.frame(knn_metrics)
rownames(knn_metrics_df) <- c("Barata", "Media", "Cara")
print(knn_metrics_df)


knn_accuracy <- conf_matrix_knn$overall["Accuracy"]
print(paste("Accuracy del modelo KNN con validación cruzada:", knn_accuracy))

```

#### Analisis con Validacion Cruzada

Podemos ver que realmente no mejoro mucho haciendo validacion cruzada mejoro de 0.65 a 0.67 con una cantidad de k ahora de 21. Habiendo aumentado a la anterior que fue de 5 , y aun asi con eso no logro mejorar en nada a nuestro modelo mas de un 2% mas. Esto indica que o bien nuestro modelo no puede ser mejorado mas o necesitamos tunear mas datos para poder determinar un mejor modelo. 

### 9.	Tanto para los modelos de regresión como de clasificación, pruebe con varios valores de los hiperparámetros ¿Qué parámetros pueden tunearse en un KNN?, use el mejor modelo del tuneo, ¿Mejoraron los resultados usando el mejor modelo ahora? Explique.

#### Modelo Regresion



```{r}





library(caret)  # Para el modelo KNN y preprocesamiento
library(Metrics)  # Para métricas de evaluación

# Cargar los datos
house_data <- read.csv("train_set.csv")

# Preprocesamiento: manejo de valores faltantes y normalización
pre_proc <- preProcess(house_data[, c("LotArea", "OverallQual", "GrLivArea", "YearBuilt", "TotRmsAbvGrd", "GarageCars", "SalePrice")], 
                       method = c("center", "scale"))
house_data_normalized <- predict(pre_proc, house_data)


set.seed(123)  # Para reproducibilidad
train_index <- createDataPartition(house_data_normalized$SalePrice, p = 0.8, list = FALSE)
train_data <- house_data_normalized[train_index, ]
test_data <- house_data_normalized[-train_index, ]


X_train <- train_data[, c("LotArea", "OverallQual", "GrLivArea", "YearBuilt", "TotRmsAbvGrd", "GarageCars")]
y_train <- train_data$SalePrice
X_test <- test_data[, c("LotArea", "OverallQual", "GrLivArea", "YearBuilt", "TotRmsAbvGrd", "GarageCars")]
y_test <- test_data$SalePrice


train_control <- trainControl(method = "cv", number = 10)  # Validación cruzada de 10 pliegues


knn_model_euclidiana <- train(
  x = X_train, y = y_train, 
  method = "knn", 
  trControl = train_control,
  tuneGrid = expand.grid(k = 5),  # Puedes ajustar el valor de k aquí
  metric = "RMSE", 
  preProcess = c("center", "scale")  # Normalización
)


knn_predictions_euclidiana <- predict(knn_model_euclidiana, X_test)


rmse_value_euclidiana <- rmse(y_test, knn_predictions_euclidiana)
print(paste("RMSE (Euclidiana):", rmse_value_euclidiana))

r_squared_euclidiana <- 1 - (sum((knn_predictions_euclidiana - y_test)^2) / sum((y_test - mean(y_test))^2))
print(paste("R² (Euclidiana):", r_squared_euclidiana))


knn_model_manhattan <- train(
  x = X_train, y = y_train, 
  method = "knn", 
  trControl = train_control,
  tuneGrid = expand.grid(k = 5),  # Ajustar k según se necesite
  metric = "RMSE", 
  preProcess = c("center", "scale"),
  dist = 1  # Distancia Manhattan
)

knn_predictions_manhattan <- predict(knn_model_manhattan, X_test)


rmse_value_manhattan <- rmse(y_test, knn_predictions_manhattan)
print(paste("RMSE (Manhattan):", rmse_value_manhattan))

r_squared_manhattan <- 1 - (sum((knn_predictions_manhattan - y_test)^2) / sum((y_test - mean(y_test))^2))
print(paste("R² (Manhattan):", r_squared_manhattan))


errors_euclidiana <- c()
for (k in 1:20) {
  knn_model_euclidiana <- train(
    x = X_train, y = y_train, 
    method = "knn", 
    trControl = train_control,
    tuneGrid = expand.grid(k = k),
    metric = "RMSE", 
    preProcess = c("center", "scale")
  )
  errors_euclidiana[k] <- knn_model_euclidiana$results$RMSE
}


errors_manhattan <- c()
for (k in 1:20) {
  knn_model_manhattan <- train(
    x = X_train, y = y_train, 
    method = "knn", 
    trControl = train_control,
    tuneGrid = expand.grid(k = k),
    metric = "RMSE", 
    preProcess = c("center", "scale"),
    dist = 1
  )
  errors_manhattan[k] <- knn_model_manhattan$results$RMSE
}




# Visualizar los errores por cada valor de k usando distancia Euclidiana
plot(1:20, errors_euclidiana, type = "b", pch = 19, col = "blue", xlab = "Valor de k", ylab = "RMSE", main = "Gráfica de RMSE vs. Valores de k (Euclidiana vs Manhattan)")

# Agregar la línea para los errores con distancia Manhattan
lines(1:20, errors_manhattan, type = "b", pch = 19, col = "red")

# Agregar la leyenda a la gráfica
legend("topright", legend = c("Euclidiana", "Manhattan"), col = c("blue", "red"), pch = 19)






```



#### Analisis de Regresion

Podemos ver que probando hasta con diferentes tipos de manera de realizar las distancias cambio a 0.4. Esto pasa al usar caret en vez de FNN si ya que un numero de K optimo es de 5.  Siendo una mejora del 20%. 


#### Modelo de Clasificacion

```{r}
library(class)
library(caret)
library(tidyverse)

# Cargar los conjuntos de datos
train_data <- read.csv("train_set.csv", stringsAsFactors = FALSE)
test_data <- read.csv("test_set.csv", stringsAsFactors = FALSE)

# Seleccionar variables relevantes
features <- c("GrLivArea", "OverallQual", "TotRmsAbvGrd")


for (feature in features) {
  train_data[[feature]][is.na(train_data[[feature]])] <- median(train_data[[feature]], na.rm = TRUE)
  test_data[[feature]][is.na(test_data[[feature]])] <- median(train_data[[feature]], na.rm = TRUE)
}

# Crear variable categórica (Barata, Media, Cara)
train_data$PriceCategory <- cut(
  train_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)

test_data$PriceCategory <- cut(
  test_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)


train_data$PriceCategory <- as.factor(train_data$PriceCategory)
test_data$PriceCategory <- as.factor(test_data$PriceCategory)


normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }
for (feature in features) {
  train_data[[feature]] <- normalize(train_data[[feature]])
  test_data[[feature]] <- normalize(test_data[[feature]])
}


tune_grid <- expand.grid(
  kmax = seq(1, 20, by = 2),     
  distance = c(1, 2),         
  kernel = c("rectangular", "triangular", "gaussian")
)





knn_tuned <- train(
  PriceCategory ~ ., 
  data = train_data[, c(features, "PriceCategory")], 
  method = "kknn",  
  tuneGrid = tune_grid
)

print(knn_tuned$bestTune)

ggplot(knn_tuned) + 
  ggtitle("Precisión del modelo KNN según parámetros") +
  xlab("Número de vecinos (k)") + 
  ylab("Accuracy") + 
  theme_minimal()

```

#### Rendimiento del mejor

```{r}
# Cargar librerías necesarias
library(caret)
library(kknn)
library(tidyverse)

# Cargar datasets
train_data <- read.csv("train_set.csv", stringsAsFactors = FALSE)
test_data <- read.csv("test_set.csv", stringsAsFactors = FALSE)

# Variables a usar
features <- c("GrLivArea", "OverallQual", "TotRmsAbvGrd")

# Imputación de valores NA
for (feature in features) {
  train_data[[feature]][is.na(train_data[[feature]])] <- median(train_data[[feature]], na.rm = TRUE)
  test_data[[feature]][is.na(test_data[[feature]])] <- median(test_data[[feature]], na.rm = TRUE)
}

# Crear variable categórica (Barata, Media, Cara)
train_data$PriceCategory <- cut(
  train_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)

test_data$PriceCategory <- cut(
  test_data$SalePrice,
  breaks = quantile(train_data$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Barata", "Media", "Cara"),
  include.lowest = TRUE
)


train_data$PriceCategory <- as.factor(train_data$PriceCategory)
test_data$PriceCategory <- as.factor(test_data$PriceCategory)


normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }
for (feature in features) {
  train_data[[feature]] <- normalize(train_data[[feature]])
  test_data[[feature]] <- normalize(test_data[[feature]])
}

# Entrenar modelo con los parámetros elegidos
knn_final <- train(
  PriceCategory ~ ., 
  data = train_data[, c(features, "PriceCategory")], 
  method = "kknn",
  tuneGrid = expand.grid(kmax = 7, distance = 1, kernel = "triangular")
)


predictions <- predict(knn_final, test_data)


conf_matrix <- confusionMatrix(predictions, test_data$PriceCategory)
print(conf_matrix)


accuracy <- conf_matrix$overall["Accuracy"]
print(paste("Accuracy del modelo KNN con kmax=7, distance=1, kernel='triangular':", accuracy))


```




#### Analisis Modelo Clasificacion

Podemos ver que nuesotro modelo de clasificacion con un kernel triangular y con un kmax de 7 y distancia de 1 fue el mejor de todos, pero realmente no mejoro mucho en la parte de clasificacion de los modelos. Pero si vemos el acurrancy y el arbol que representa el acurrancy por cada modelo con diferentes parametros no pasa de 0.67 en el mejor de los casos lo cual indica que nuestro modelo en el aspecto de clasificacion esta rindiendo bastante pesimo con respecto a otros. 


### 10.	Compare la eficiencia del algoritmo con el resultado obtenido con el árbol de decisión (el de clasificación), el modelo de random forest y el de naive bayes que hizo en las entregas pasadas. ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?.




#### Modelos de Regresion

```{r}
# Datos de regresión
regresion <- data.frame(
  Modelo = c("KNN", "Naive Bayes", "Árbol de Regresión"),
  MSE = c(0.1600,0.05044311, 1658823049)
)

# Gráfico de MSE (Regresión)
ggplot(regresion, aes(x = Modelo, y = MSE, fill = Modelo)) +
  geom_bar(stat = "identity", color = "black", alpha = 0.8) +
  labs(title = "Comparación de MSE en Modelos de Regresión",
       x = "Modelo",
       y = "MSE") +
  theme_minimal() +
  theme(legend.position = "none")
```

#### Analisis modelos de Regresion

Podemos ver que nuestros modelos de regresion el que le sigue estando mejor es naive bayes y KNN realmente no mejoro mucho con respecto a naive bayes,  pero si es un buen modelo, de hecho es bastante decente para poder hacer predicciones con regresion ya que si tiene un buen RMSE a diferencia de hacerlo por clasificacion. Muy probablemente por la naturaleza de KNN que necesita que los datos sean continuos y al clasificar dependiendo mas por distancias que por correlacion entre los datos. 


#### Modelos de Clasificacion

```{r}


library(ggplot2)

# Datos de clasificación
clasificacion <- data.frame(
  Modelo = c("KNN","Naive Bayes", "Random Forest", "Árbol de Clasificación"),
  Accuracy = c(0.67, 0.8041237, 0.9816934, 0.7414188)
)

# Gráfico de Accuracy (Clasificación)
ggplot(clasificacion, aes(x = Modelo, y = Accuracy, fill = Modelo)) +
  geom_bar(stat = "identity", color = "black", alpha = 0.8) +
  labs(title = "Comparación de Accuracy en Modelos de Clasificación",
       x = "Modelo",
       y = "Accuracy") +
  theme_minimal() +
  theme(legend.position = "none")

```


#### Analisis modelos de clasificacion


Aqui podemos ver que KNN es el peor de los 4, siendo Random Forest el que sigue liderando con un 0.9 de acurrancy a diferencia de KNN podemos ver que realmente nuestro modelo no ha mejorado en nada la prediccion de clasificacion . 

Esto puede deberse a como mencionamos anteriormente la naturaleza de KNN al ser un modelo que mide distancias entre cada punto para poder realizar clasificaciones en vez de guiarse por correlaciones de los datos, la naturaleza de las variables y la causualidad de cada variable con respecto al objetivo, ademas de no ser muy descriptivo con respecto a que sucede con nuestras variables ya que no nos dijo realmente el comportamiento que suele tener a diferencia de Random Forest y de Arbol de Clasificacion. 

De entre todos el que se suele tardar mas es Random Forest, esto porque suele tener mejor rendimiento, KNN seguira teniendo malores resultados sin embargo fue el mas rapido de los metodos de clasificacion antes vistos por lo que puede ser muy util de usar en el contexto de realizar un analisis rapido o requerir un modelo optimizado para grandes volumnenes de datos. 


## Conclusion

Podemos ver que KNN no represento una mejora para los modelos anteriormente vistos, aun asi si es bastante eficiente al momento de hacer regresion , pero es poco recomendable usarlo al clasificar nuestra variable SalePrice, ademas que a diferencia del arbol de clasificacion no nos indica mas puntualidades de nuestra variable objetivo sino que solmanete realiza su prediccion. 

Sin embargo resulto ser uno de los mas rapidos hasta ahora por lo que puede ser recomendable su uso en caso de necesitar prediccion mas optimizada que precisa. Aun con ello no se recomienda usarlo debido a su bajo acurrancy para clasificacion. 


